{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cs8nL5H6aejY"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "\n",
    "\n",
    "#  TIP: 1. Research and import desired feature selection methods from https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\n",
    "#       2. For k-fold cross validation, consider https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html \n",
    "#                                         and/or https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "#       3. Research and import desired classification algorithms from https://scikit-learn.org/stable/supervised_learning.html\n",
    "#       4. Research and import desired clustering algorithms from https://scikit-learn.org/stable/modules/clustering.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vr0rAS9fayqV"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "For each question, a rough outline has been provided to help you get started under \"Part 1.x.x: Work\". Feel free to either follow the outline or use your own method for solving the problem. In either case, however, please make sure to include your work in these sections and fill in your answer in the cell titled \"Part 1.x.x: Answer\".\n",
    "\n",
    "**Embedding Images in the Notebook**\n",
    "\n",
    "To upload an image in a markdown cell in Jupyter Notebook:\n",
    "1. Go to the menu bar and select Edit -> Insert Image.\n",
    "\n",
    "2. Select image from your disk and upload.\n",
    "\n",
    "3. Press Ctrl+Enter or Shift+Enter.\n",
    "\n",
    "This will make the image as part of the notebook and you don't need to upload it in the directory\n",
    "\n",
    "**Export Jupyter Notebooks**  \n",
    "In your local computer, open the notebook you would like to export and navigate to 'File' at the top menu bar. By clickling 'File', you can find 'Download as' in the drop-down menu. Select the format you want to export the notebook as: either directly as a pdf, or if you download it as an html file, use a website like [html2pdf.com](https://html2pdf.com) to convert it to a pdf file for submission on Gradescope.\n",
    "\n",
    "Colab does not seem to support exporting their notebooks to other formats, so if you choose to use Colab, you will need to download the notebook as an .ipynb file before following the steps above on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcsbfHdddGf8"
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7Kljl7JdPsB"
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "591CSvGJdRJ1"
   },
   "outputs": [],
   "source": [
    "PATH_TO_Q1_DATA = 'data/HW2_Q1_DATA.csv'\n",
    "df = pd.read_csv(PATH_TO_Q1_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4E-BP1</th>\n",
       "      <th>ADA</th>\n",
       "      <th>AREG</th>\n",
       "      <th>AXIN1</th>\n",
       "      <th>BACH1</th>\n",
       "      <th>BIRC2</th>\n",
       "      <th>BTN3A2</th>\n",
       "      <th>CASP-8</th>\n",
       "      <th>CCL11</th>\n",
       "      <th>CCL19</th>\n",
       "      <th>CCL20</th>\n",
       "      <th>CCL23</th>\n",
       "      <th>CCL25</th>\n",
       "      <th>CCL28</th>\n",
       "      <th>CCL3</th>\n",
       "      <th>CCL4</th>\n",
       "      <th>CD244</th>\n",
       "      <th>CD28</th>\n",
       "      <th>CD40</th>\n",
       "      <th>CD5</th>\n",
       "      <th>CD6</th>\n",
       "      <th>CD83</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>CDCP1</th>\n",
       "      <th>CDSN</th>\n",
       "      <th>CKAP4</th>\n",
       "      <th>CLEC4A</th>\n",
       "      <th>CLEC4C</th>\n",
       "      <th>CLEC4D</th>\n",
       "      <th>CLEC4G</th>\n",
       "      <th>CLEC7A</th>\n",
       "      <th>CNTNAP2</th>\n",
       "      <th>CSF-1</th>\n",
       "      <th>CST5</th>\n",
       "      <th>CX3CL1</th>\n",
       "      <th>CXADR</th>\n",
       "      <th>CXCL1</th>\n",
       "      <th>CXCL10</th>\n",
       "      <th>CXCL11</th>\n",
       "      <th>CXCL5</th>\n",
       "      <th>CXCL6</th>\n",
       "      <th>CXCL9</th>\n",
       "      <th>DCBLD2</th>\n",
       "      <th>DCTN1</th>\n",
       "      <th>DFFA</th>\n",
       "      <th>DNER</th>\n",
       "      <th>DPP10</th>\n",
       "      <th>EDAR</th>\n",
       "      <th>EIF4G1</th>\n",
       "      <th>EIF5A</th>\n",
       "      <th>EN-RAGE</th>\n",
       "      <th>FAM3B</th>\n",
       "      <th>FCRL6</th>\n",
       "      <th>FGF-19</th>\n",
       "      <th>FGF-21</th>\n",
       "      <th>Flt3L</th>\n",
       "      <th>GLB1</th>\n",
       "      <th>HCLS1</th>\n",
       "      <th>HEXIM1</th>\n",
       "      <th>HGF</th>\n",
       "      <th>HNMT</th>\n",
       "      <th>HSD11B1</th>\n",
       "      <th>IFN-gamma</th>\n",
       "      <th>IFNLR1</th>\n",
       "      <th>IL-10RA</th>\n",
       "      <th>IL-10RB</th>\n",
       "      <th>IL-12B</th>\n",
       "      <th>IL-17A</th>\n",
       "      <th>IL-17C</th>\n",
       "      <th>IL-18R1</th>\n",
       "      <th>IL-20RA</th>\n",
       "      <th>IL18</th>\n",
       "      <th>IL5</th>\n",
       "      <th>IL6</th>\n",
       "      <th>IL7</th>\n",
       "      <th>IL8</th>\n",
       "      <th>IRAK1</th>\n",
       "      <th>ITGA11</th>\n",
       "      <th>ITGA6</th>\n",
       "      <th>ITGB6</th>\n",
       "      <th>ITM2A</th>\n",
       "      <th>JUN</th>\n",
       "      <th>KLRD1</th>\n",
       "      <th>KRT19</th>\n",
       "      <th>LAG3</th>\n",
       "      <th>LAMP3</th>\n",
       "      <th>LAP TGF-beta-1</th>\n",
       "      <th>LIF-R</th>\n",
       "      <th>LILRB4</th>\n",
       "      <th>LY75</th>\n",
       "      <th>MASP1</th>\n",
       "      <th>MCP-1</th>\n",
       "      <th>MCP-2</th>\n",
       "      <th>MCP-4</th>\n",
       "      <th>MILR1</th>\n",
       "      <th>MMP-1</th>\n",
       "      <th>MMP-10</th>\n",
       "      <th>NCR1</th>\n",
       "      <th>NT-3</th>\n",
       "      <th>NTF4</th>\n",
       "      <th>OPG</th>\n",
       "      <th>OSM</th>\n",
       "      <th>PADI2</th>\n",
       "      <th>PD-L1</th>\n",
       "      <th>PIK3AP1</th>\n",
       "      <th>PPP1R9B</th>\n",
       "      <th>PRDX1</th>\n",
       "      <th>PRDX3</th>\n",
       "      <th>PRDX5</th>\n",
       "      <th>PSIP1</th>\n",
       "      <th>PTH1R</th>\n",
       "      <th>SCF</th>\n",
       "      <th>SH2D1A</th>\n",
       "      <th>SIRT2</th>\n",
       "      <th>SIT1</th>\n",
       "      <th>SLAMF1</th>\n",
       "      <th>SPRY2</th>\n",
       "      <th>SRPK2</th>\n",
       "      <th>STAMBP</th>\n",
       "      <th>STC1</th>\n",
       "      <th>TGF-alpha</th>\n",
       "      <th>TNF</th>\n",
       "      <th>TNFB</th>\n",
       "      <th>TNFRSF9</th>\n",
       "      <th>TNFSF14</th>\n",
       "      <th>TRAIL</th>\n",
       "      <th>TRANCE</th>\n",
       "      <th>TREM1</th>\n",
       "      <th>TRIM21</th>\n",
       "      <th>TWEAK</th>\n",
       "      <th>uPA</th>\n",
       "      <th>VEGFA</th>\n",
       "      <th>ZBTB16</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.718344</td>\n",
       "      <td>5.734644</td>\n",
       "      <td>13.165561</td>\n",
       "      <td>6.770850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.756987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.161444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.545201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.817527</td>\n",
       "      <td>7.508032</td>\n",
       "      <td>2.422742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.843969</td>\n",
       "      <td>18.773615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.730868</td>\n",
       "      <td>7.455245</td>\n",
       "      <td>26.659559</td>\n",
       "      <td>4.189390</td>\n",
       "      <td>1.076872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.826296</td>\n",
       "      <td>7.788437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.220314</td>\n",
       "      <td>1.109837</td>\n",
       "      <td>10.874609</td>\n",
       "      <td>5.293797</td>\n",
       "      <td>9.480353</td>\n",
       "      <td>3.203696</td>\n",
       "      <td>6.252064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.693942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.368058</td>\n",
       "      <td>13.041884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.637007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.397451</td>\n",
       "      <td>3.405191</td>\n",
       "      <td>1.438115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.779473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.286780</td>\n",
       "      <td>4.291350</td>\n",
       "      <td>4.174334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.912544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.399080</td>\n",
       "      <td>17.348777</td>\n",
       "      <td>11.560710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>5.170512</td>\n",
       "      <td>4.020843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.436370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.622146</td>\n",
       "      <td>4.472475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.039560</td>\n",
       "      <td>15.033599</td>\n",
       "      <td>12.192460</td>\n",
       "      <td>2.470746</td>\n",
       "      <td>13.304297</td>\n",
       "      <td>7.517567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.864877</td>\n",
       "      <td>4.191008</td>\n",
       "      <td>3.132020</td>\n",
       "      <td>8.541414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.163430</td>\n",
       "      <td>1.620337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.856916</td>\n",
       "      <td>9.504446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.975596</td>\n",
       "      <td>16.192791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>11.178848</td>\n",
       "      <td>15.181206</td>\n",
       "      <td>14.145702</td>\n",
       "      <td>16.986303</td>\n",
       "      <td>8.658794</td>\n",
       "      <td>7.202860</td>\n",
       "      <td>0.964152</td>\n",
       "      <td>2.125859</td>\n",
       "      <td>3.510396</td>\n",
       "      <td>15.197014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.309584</td>\n",
       "      <td>8.302339</td>\n",
       "      <td>12.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998187</td>\n",
       "      <td>17.015074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.462921</td>\n",
       "      <td>8.162390</td>\n",
       "      <td>3.209589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.846367</td>\n",
       "      <td>CoV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.791418</td>\n",
       "      <td>5.884233</td>\n",
       "      <td>0.396271</td>\n",
       "      <td>12.521125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.558042</td>\n",
       "      <td>4.814161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555607</td>\n",
       "      <td>10.962094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.648440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.966805</td>\n",
       "      <td>2.731494</td>\n",
       "      <td>0.699221</td>\n",
       "      <td>11.196644</td>\n",
       "      <td>5.726753</td>\n",
       "      <td>6.832898</td>\n",
       "      <td>10.350866</td>\n",
       "      <td>0.239732</td>\n",
       "      <td>6.455786</td>\n",
       "      <td>4.033267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.942073</td>\n",
       "      <td>3.111585</td>\n",
       "      <td>33.275970</td>\n",
       "      <td>3.360276</td>\n",
       "      <td>6.135610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.859586</td>\n",
       "      <td>6.974876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.929481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.068265</td>\n",
       "      <td>5.977234</td>\n",
       "      <td>19.969867</td>\n",
       "      <td>14.074089</td>\n",
       "      <td>4.800421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.175309</td>\n",
       "      <td>5.423078</td>\n",
       "      <td>43.495684</td>\n",
       "      <td>1.933688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.305734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.627888</td>\n",
       "      <td>2.767051</td>\n",
       "      <td>2.895586</td>\n",
       "      <td>15.693953</td>\n",
       "      <td>7.802739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.635262</td>\n",
       "      <td>32.458745</td>\n",
       "      <td>1.653591</td>\n",
       "      <td>11.295072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.852373</td>\n",
       "      <td>6.740466</td>\n",
       "      <td>5.331868</td>\n",
       "      <td>4.422822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.841615</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>6.471288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.305014</td>\n",
       "      <td>11.732910</td>\n",
       "      <td>5.069960</td>\n",
       "      <td>6.585386</td>\n",
       "      <td>9.957475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.199421</td>\n",
       "      <td>2.698841</td>\n",
       "      <td>0.267144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.372084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.774374</td>\n",
       "      <td>13.806183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.643473</td>\n",
       "      <td>15.595458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.105447</td>\n",
       "      <td>9.701070</td>\n",
       "      <td>1.397358</td>\n",
       "      <td>2.375529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.456537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.482231</td>\n",
       "      <td>10.512135</td>\n",
       "      <td>6.418627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.694330</td>\n",
       "      <td>2.552504</td>\n",
       "      <td>20.129469</td>\n",
       "      <td>14.268805</td>\n",
       "      <td>15.909556</td>\n",
       "      <td>1.923489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.683408</td>\n",
       "      <td>3.810757</td>\n",
       "      <td>5.165126</td>\n",
       "      <td>12.456605</td>\n",
       "      <td>6.177402</td>\n",
       "      <td>5.582112</td>\n",
       "      <td>28.143195</td>\n",
       "      <td>8.333056</td>\n",
       "      <td>1.801868</td>\n",
       "      <td>2.697739</td>\n",
       "      <td>9.918408</td>\n",
       "      <td>1.576225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.988058</td>\n",
       "      <td>CoV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.303576</td>\n",
       "      <td>14.225052</td>\n",
       "      <td>3.579328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.902642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.829464</td>\n",
       "      <td>6.176597</td>\n",
       "      <td>36.725478</td>\n",
       "      <td>14.500758</td>\n",
       "      <td>2.852927</td>\n",
       "      <td>10.440139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.984527</td>\n",
       "      <td>12.205972</td>\n",
       "      <td>4.904689</td>\n",
       "      <td>6.295782</td>\n",
       "      <td>5.977952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.676186</td>\n",
       "      <td>21.463649</td>\n",
       "      <td>10.210970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.580720</td>\n",
       "      <td>6.555678</td>\n",
       "      <td>11.049189</td>\n",
       "      <td>7.134474</td>\n",
       "      <td>13.464460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.716326</td>\n",
       "      <td>21.698020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.640113</td>\n",
       "      <td>17.448447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.834174</td>\n",
       "      <td>8.478314</td>\n",
       "      <td>3.700956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.284261</td>\n",
       "      <td>1.611970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.126854</td>\n",
       "      <td>14.547810</td>\n",
       "      <td>0.465372</td>\n",
       "      <td>2.051328</td>\n",
       "      <td>12.058449</td>\n",
       "      <td>4.064884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.906368</td>\n",
       "      <td>19.271130</td>\n",
       "      <td>1.949508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.522496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.872648</td>\n",
       "      <td>2.216933</td>\n",
       "      <td>4.436103</td>\n",
       "      <td>7.143954</td>\n",
       "      <td>8.589794</td>\n",
       "      <td>14.503386</td>\n",
       "      <td>6.697591</td>\n",
       "      <td>22.231499</td>\n",
       "      <td>4.987172</td>\n",
       "      <td>17.674558</td>\n",
       "      <td>4.813506</td>\n",
       "      <td>7.469346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.423389</td>\n",
       "      <td>12.371840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.042771</td>\n",
       "      <td>21.624428</td>\n",
       "      <td>1.761447</td>\n",
       "      <td>2.059286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.540848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.381173</td>\n",
       "      <td>10.981585</td>\n",
       "      <td>13.649523</td>\n",
       "      <td>12.205179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.144046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.248831</td>\n",
       "      <td>8.679000</td>\n",
       "      <td>4.997343</td>\n",
       "      <td>3.723973</td>\n",
       "      <td>3.271037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.698682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.009661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.169588</td>\n",
       "      <td>2.759763</td>\n",
       "      <td>14.169685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.877548</td>\n",
       "      <td>10.189094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611127</td>\n",
       "      <td>4.728766</td>\n",
       "      <td>7.834599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.891360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.508738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.975069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.386741</td>\n",
       "      <td>7.641283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.691916</td>\n",
       "      <td>8.765778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CoV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.979020</td>\n",
       "      <td>3.951806</td>\n",
       "      <td>13.588954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.762301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.641054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.006941</td>\n",
       "      <td>2.533738</td>\n",
       "      <td>13.983938</td>\n",
       "      <td>16.016056</td>\n",
       "      <td>20.319857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.620696</td>\n",
       "      <td>10.010847</td>\n",
       "      <td>3.478779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.270852</td>\n",
       "      <td>0.234896</td>\n",
       "      <td>4.900533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.937115</td>\n",
       "      <td>15.856580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.769897</td>\n",
       "      <td>7.372922</td>\n",
       "      <td>8.552411</td>\n",
       "      <td>13.400732</td>\n",
       "      <td>10.923518</td>\n",
       "      <td>8.712527</td>\n",
       "      <td>14.060745</td>\n",
       "      <td>9.543912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.545709</td>\n",
       "      <td>5.554199</td>\n",
       "      <td>25.910790</td>\n",
       "      <td>6.253145</td>\n",
       "      <td>3.592633</td>\n",
       "      <td>17.705845</td>\n",
       "      <td>11.529770</td>\n",
       "      <td>1.074994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.502713</td>\n",
       "      <td>6.363347</td>\n",
       "      <td>0.455958</td>\n",
       "      <td>10.095157</td>\n",
       "      <td>1.414611</td>\n",
       "      <td>5.980262</td>\n",
       "      <td>1.353980</td>\n",
       "      <td>1.345516</td>\n",
       "      <td>29.828019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736009</td>\n",
       "      <td>7.229042</td>\n",
       "      <td>8.788089</td>\n",
       "      <td>17.088633</td>\n",
       "      <td>16.688903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.350538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.035066</td>\n",
       "      <td>10.251878</td>\n",
       "      <td>11.228750</td>\n",
       "      <td>2.936814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.001684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.005881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.929554</td>\n",
       "      <td>0.496456</td>\n",
       "      <td>1.081126</td>\n",
       "      <td>2.451960</td>\n",
       "      <td>2.583517</td>\n",
       "      <td>1.301595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.319082</td>\n",
       "      <td>26.998480</td>\n",
       "      <td>0.579181</td>\n",
       "      <td>7.093564</td>\n",
       "      <td>12.440918</td>\n",
       "      <td>13.058358</td>\n",
       "      <td>0.806794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.224822</td>\n",
       "      <td>32.252334</td>\n",
       "      <td>6.083160</td>\n",
       "      <td>4.198913</td>\n",
       "      <td>7.043943</td>\n",
       "      <td>17.615603</td>\n",
       "      <td>11.997634</td>\n",
       "      <td>5.104573</td>\n",
       "      <td>1.268538</td>\n",
       "      <td>9.909172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.217358</td>\n",
       "      <td>0.713961</td>\n",
       "      <td>2.341105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.486709</td>\n",
       "      <td>2.207701</td>\n",
       "      <td>4.694460</td>\n",
       "      <td>2.243460</td>\n",
       "      <td>6.075966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.599597</td>\n",
       "      <td>12.328922</td>\n",
       "      <td>4.723975</td>\n",
       "      <td>18.016696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.973071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.374204</td>\n",
       "      <td>5.073757</td>\n",
       "      <td>0.349745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.595654</td>\n",
       "      <td>7.518821</td>\n",
       "      <td>2.431795</td>\n",
       "      <td>9.712949</td>\n",
       "      <td>13.143095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.051765</td>\n",
       "      <td>Kawasaki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.169370</td>\n",
       "      <td>6.101314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.860173</td>\n",
       "      <td>25.107465</td>\n",
       "      <td>17.558198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.254488</td>\n",
       "      <td>24.811130</td>\n",
       "      <td>6.211186</td>\n",
       "      <td>1.851991</td>\n",
       "      <td>0.570189</td>\n",
       "      <td>8.988984</td>\n",
       "      <td>13.393828</td>\n",
       "      <td>1.935768</td>\n",
       "      <td>26.185549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.558669</td>\n",
       "      <td>10.409517</td>\n",
       "      <td>2.649508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.171800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.109051</td>\n",
       "      <td>2.436654</td>\n",
       "      <td>12.533702</td>\n",
       "      <td>14.556793</td>\n",
       "      <td>0.930027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.467879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.324421</td>\n",
       "      <td>20.431823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.112190</td>\n",
       "      <td>1.603928</td>\n",
       "      <td>3.921144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.938515</td>\n",
       "      <td>7.833951</td>\n",
       "      <td>0.557077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.598639</td>\n",
       "      <td>4.593993</td>\n",
       "      <td>3.623229</td>\n",
       "      <td>57.541911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.123271</td>\n",
       "      <td>1.600753</td>\n",
       "      <td>19.435787</td>\n",
       "      <td>10.058789</td>\n",
       "      <td>18.151589</td>\n",
       "      <td>7.014215</td>\n",
       "      <td>1.642917</td>\n",
       "      <td>8.400721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.120824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.641042</td>\n",
       "      <td>0.106581</td>\n",
       "      <td>8.346420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.129071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.897908</td>\n",
       "      <td>19.545565</td>\n",
       "      <td>7.265863</td>\n",
       "      <td>7.804504</td>\n",
       "      <td>1.687638</td>\n",
       "      <td>4.757626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.194960</td>\n",
       "      <td>8.191169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.375276</td>\n",
       "      <td>3.458710</td>\n",
       "      <td>1.990674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.487413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.533439</td>\n",
       "      <td>5.711122</td>\n",
       "      <td>9.125687</td>\n",
       "      <td>2.866388</td>\n",
       "      <td>5.501048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.366002</td>\n",
       "      <td>16.367790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.443935</td>\n",
       "      <td>1.472136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.315591</td>\n",
       "      <td>8.835188</td>\n",
       "      <td>9.302537</td>\n",
       "      <td>1.896896</td>\n",
       "      <td>18.581458</td>\n",
       "      <td>14.406221</td>\n",
       "      <td>3.967572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.943378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.013267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.057533</td>\n",
       "      <td>1.054401</td>\n",
       "      <td>16.644724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.717587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.371679</td>\n",
       "      <td>22.049279</td>\n",
       "      <td>7.630129</td>\n",
       "      <td>19.353450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MIS-C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      4E-BP1        ADA       AREG      AXIN1      BACH1     BIRC2     BTN3A2  \\\n",
       "0  27.718344   5.734644  13.165561   6.770850   0.000000  9.756987   0.000000   \n",
       "1   0.000000  13.791418   5.884233   0.396271  12.521125  0.000000   7.558042   \n",
       "2   0.000000   0.000000   2.303576  14.225052   3.579328  0.000000   7.902642   \n",
       "3  29.979020   3.951806  13.588954   0.000000  10.762301  0.000000   0.000000   \n",
       "4   7.169370   6.101314   0.000000   0.000000   0.000000  0.000000  16.860173   \n",
       "\n",
       "      CASP-8      CCL11     CCL19      CCL20      CCL23      CCL25      CCL28  \\\n",
       "0   6.161444   0.000000  3.545201   0.000000   8.817527   7.508032   2.422742   \n",
       "1   4.814161   0.000000  0.000000   0.555607  10.962094   0.000000   2.648440   \n",
       "2   0.000000   0.896923  0.000000   0.000000   6.829464   6.176597  36.725478   \n",
       "3   4.641054   0.000000  5.006941   2.533738  13.983938  16.016056  20.319857   \n",
       "4  25.107465  17.558198  0.000000  14.254488  24.811130   6.211186   1.851991   \n",
       "\n",
       "        CCL3       CCL4      CD244      CD28       CD40        CD5        CD6  \\\n",
       "0   0.000000   6.843969  18.773615  0.000000  18.730868   7.455245  26.659559   \n",
       "1   0.000000   0.000000   7.966805  2.731494   0.699221  11.196644   5.726753   \n",
       "2  14.500758   2.852927  10.440139  0.000000   1.984527  12.205972   4.904689   \n",
       "3   0.000000  19.620696  10.010847  3.478779   0.000000   7.270852   0.234896   \n",
       "4   0.570189   8.988984  13.393828  1.935768  26.185549   0.000000   8.558669   \n",
       "\n",
       "        CD83       CD8A     CDCP1       CDSN      CKAP4     CLEC4A    CLEC4C  \\\n",
       "0   4.189390   1.076872  0.000000   0.000000   0.000000  11.826296  7.788437   \n",
       "1   6.832898  10.350866  0.239732   6.455786   4.033267   0.000000  0.000000   \n",
       "2   6.295782   5.977952  0.000000  35.676186  21.463649  10.210970  0.000000   \n",
       "3   4.900533   0.000000  9.937115  15.856580   0.000000   5.769897  7.372922   \n",
       "4  10.409517   2.649508  0.000000   0.000000   0.000000   4.171800  0.000000   \n",
       "\n",
       "      CLEC4D     CLEC4G     CLEC7A    CNTNAP2      CSF-1       CST5    CX3CL1  \\\n",
       "0   0.000000  16.220314   1.109837  10.874609   5.293797   9.480353  3.203696   \n",
       "1  18.942073   3.111585  33.275970   3.360276   6.135610   0.000000  0.000000   \n",
       "2  13.580720   6.555678  11.049189   7.134474  13.464460   0.000000  0.000000   \n",
       "3   8.552411  13.400732  10.923518   8.712527  14.060745   9.543912  0.000000   \n",
       "4   0.000000   0.000000  20.109051   2.436654  12.533702  14.556793  0.930027   \n",
       "\n",
       "      CXADR     CXCL1     CXCL10    CXCL11      CXCL5      CXCL6      CXCL9  \\\n",
       "0  6.252064  0.000000  26.693942  0.000000   0.000000   7.368058  13.041884   \n",
       "1  0.000000  1.859586   6.974876  0.000000  16.929481   0.000000  13.068265   \n",
       "2  0.000000  7.716326  21.698020  0.000000   0.000000   3.640113  17.448447   \n",
       "3  6.545709  5.554199  25.910790  6.253145   3.592633  17.705845  11.529770   \n",
       "4  0.000000  0.000000   8.467879  0.000000   0.000000  16.324421  20.431823   \n",
       "\n",
       "     DCBLD2      DCTN1       DFFA       DNER     DPP10       EDAR    EIF4G1  \\\n",
       "0  0.000000   9.637007   0.000000  13.397451  3.405191   1.438115  0.000000   \n",
       "1  5.977234  19.969867  14.074089   4.800421  0.000000   3.175309  5.423078   \n",
       "2  0.000000   7.834174   8.478314   3.700956  0.000000   0.000000  8.284261   \n",
       "3  1.074994   0.000000   4.502713   6.363347  0.455958  10.095157  1.414611   \n",
       "4  0.000000   0.000000   0.000000  13.112190  1.603928   3.921144  0.000000   \n",
       "\n",
       "       EIF5A   EN-RAGE     FAM3B      FCRL6    FGF-19     FGF-21      Flt3L  \\\n",
       "0   0.779473  0.000000  3.286780   4.291350  4.174334   0.000000   8.912544   \n",
       "1  43.495684  1.933688  0.000000   8.305734  0.000000  31.627888   2.767051   \n",
       "2   1.611970  0.000000  4.126854  14.547810  0.465372   2.051328  12.058449   \n",
       "3   5.980262  1.353980  1.345516  29.828019  0.000000   0.000000   0.736009   \n",
       "4  21.938515  7.833951  0.557077   0.000000  0.000000  15.598639   4.593993   \n",
       "\n",
       "       GLB1      HCLS1     HEXIM1        HGF      HNMT    HSD11B1  IFN-gamma  \\\n",
       "0  0.000000  15.399080  17.348777  11.560710  0.000000   0.000000   0.815476   \n",
       "1  2.895586  15.693953   7.802739   0.000000  0.000000   5.635262  32.458745   \n",
       "2  4.064884   0.000000  19.906368  19.271130  1.949508   0.000000   0.000000   \n",
       "3  7.229042   8.788089  17.088633  16.688903  0.000000   0.000000   6.350538   \n",
       "4  3.623229  57.541911   0.000000   5.123271  1.600753  19.435787  10.058789   \n",
       "\n",
       "      IFNLR1    IL-10RA   IL-10RB     IL-12B     IL-17A     IL-17C   IL-18R1  \\\n",
       "0   5.170512   4.020843  0.000000   0.000000   2.436370   0.000000  0.000000   \n",
       "1   1.653591  11.295072  0.000000   7.852373   6.740466   5.331868  4.422822   \n",
       "2   0.000000   2.522496  0.000000   6.872648   2.216933   4.436103  7.143954   \n",
       "3   0.000000   0.000000  0.000000  31.035066  10.251878  11.228750  2.936814   \n",
       "4  18.151589   7.014215  1.642917   8.400721   0.000000  15.120824  0.000000   \n",
       "\n",
       "    IL-20RA       IL18       IL5        IL6       IL7        IL8     IRAK1  \\\n",
       "0  0.000000   1.622146  4.472475   0.000000  0.000000   0.000000  8.039560   \n",
       "1  0.000000   0.000000  0.841615   0.251800  6.471288   0.000000  2.305014   \n",
       "2  8.589794  14.503386  6.697591  22.231499  4.987172  17.674558  4.813506   \n",
       "3  0.000000  12.001684  0.000000  14.005881  0.000000   9.929554  0.496456   \n",
       "4  3.641042   0.106581  8.346420   0.000000  0.000000  16.129071  0.000000   \n",
       "\n",
       "      ITGA11      ITGA6      ITGB6      ITM2A       JUN     KLRD1      KRT19  \\\n",
       "0  15.033599  12.192460   2.470746  13.304297  7.517567  0.000000   7.864877   \n",
       "1  11.732910   5.069960   6.585386   9.957475  0.000000  0.237587   0.000000   \n",
       "2   7.469346   0.000000  10.423389  12.371840  0.000000  6.042771  21.624428   \n",
       "3   1.081126   2.451960   2.583517   1.301595  0.000000  0.000000   9.319082   \n",
       "4  11.897908  19.545565   7.265863   7.804504  1.687638  4.757626   0.000000   \n",
       "\n",
       "        LAG3      LAMP3  LAP TGF-beta-1      LIF-R     LILRB4      LY75  \\\n",
       "0   4.191008   3.132020        8.541414   0.000000   9.163430  1.620337   \n",
       "1   1.785264   0.000000        7.199421   2.698841   0.267144  0.000000   \n",
       "2   1.761447   2.059286        0.000000   5.540848   0.000000  0.000000   \n",
       "3  26.998480   0.579181        7.093564  12.440918  13.058358  0.806794   \n",
       "4   0.000000  24.194960        8.191169   0.000000   9.375276  3.458710   \n",
       "\n",
       "       MASP1      MCP-1      MCP-2      MCP-4     MILR1      MMP-1     MMP-10  \\\n",
       "0   0.000000   0.000000   0.000000   0.000000  0.000000  28.856916   9.504446   \n",
       "1   9.372084   0.000000   7.774374  13.806183  0.000000   0.000000   4.643473   \n",
       "2  14.381173  10.981585  13.649523  12.205179  0.000000   8.144046   0.000000   \n",
       "3   0.000000   2.224822  32.252334   6.083160  4.198913   7.043943  17.615603   \n",
       "4   1.990674   0.000000   3.487413   0.000000  0.000000   4.533439   5.711122   \n",
       "\n",
       "        NCR1      NT-3      NTF4        OPG        OSM      PADI2      PD-L1  \\\n",
       "0   0.000000  0.000000  3.975596  16.192791   0.000000   0.000000   0.000000   \n",
       "1  15.595458  0.000000  0.000000  10.105447   9.701070   1.397358   2.375529   \n",
       "2   3.248831  8.679000  4.997343   3.723973   3.271037   0.000000  15.698682   \n",
       "3  11.997634  5.104573  1.268538   9.909172   0.000000   0.000000   3.217358   \n",
       "4   9.125687  2.866388  5.501048   0.000000  14.366002  16.367790   0.000000   \n",
       "\n",
       "    PIK3AP1    PPP1R9B      PRDX1      PRDX3      PRDX5      PSIP1     PTH1R  \\\n",
       "0  0.985249  11.178848  15.181206  14.145702  16.986303   8.658794  7.202860   \n",
       "1  0.000000  13.456537   0.000000   0.000000   7.482231  10.512135  6.418627   \n",
       "2  0.000000   0.000000   0.000000   6.009661   0.000000   4.169588  2.759763   \n",
       "3  0.713961   2.341105   0.000000   2.486709   2.207701   4.694460  2.243460   \n",
       "4  6.443935   1.472136   0.000000   5.315591   8.835188   9.302537  1.896896   \n",
       "\n",
       "         SCF     SH2D1A     SIRT2       SIT1     SLAMF1      SPRY2      SRPK2  \\\n",
       "0   0.964152   2.125859  3.510396  15.197014   0.000000   0.000000   0.000000   \n",
       "1   0.000000  15.694330  2.552504  20.129469  14.268805  15.909556   1.923489   \n",
       "2  14.169685   0.000000  1.877548  10.189094   0.000000   0.611127   4.728766   \n",
       "3   6.075966   0.000000  0.000000   8.599597  12.328922   4.723975  18.016696   \n",
       "4  18.581458  14.406221  3.967572   0.000000   6.943378   0.000000   0.000000   \n",
       "\n",
       "     STAMBP       STC1  TGF-alpha       TNF       TNFB    TNFRSF9   TNFSF14  \\\n",
       "0  6.309584   8.302339  12.000191  0.000000   0.998187  17.015074  0.000000   \n",
       "1  0.000000  12.683408   3.810757  5.165126  12.456605   6.177402  5.582112   \n",
       "2  7.834599   0.000000   5.891360  0.000000  11.508738   0.000000  8.975069   \n",
       "3  0.000000  11.973071   0.000000  0.000000  17.374204   5.073757  0.349745   \n",
       "4  5.013267   0.000000   0.000000  5.057533   1.054401  16.644724  0.000000   \n",
       "\n",
       "       TRAIL     TRANCE     TREM1     TRIM21      TWEAK        uPA  VEGFA  \\\n",
       "0   0.000000   0.000000  0.000000  10.462921   8.162390   3.209589    0.0   \n",
       "1  28.143195   8.333056  1.801868   2.697739   9.918408   1.576225    0.0   \n",
       "2   0.000000  10.386741  7.641283   0.000000  11.691916   8.765778    0.0   \n",
       "3   0.000000  19.595654  7.518821   2.431795   9.712949  13.143095    0.0   \n",
       "4   5.717587   0.000000  6.371679  22.049279   7.630129  19.353450    0.0   \n",
       "\n",
       "     ZBTB16 Condition  \n",
       "0  7.846367      CoV2  \n",
       "1  1.988058      CoV2  \n",
       "2  0.000000      CoV2  \n",
       "3  5.051765  Kawasaki  \n",
       "4  0.000000     MIS-C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # show all columns with head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fd30753ce80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram by condition just to get an idea for the data\n",
    "sns.displot(df, x=\"Condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='AREG', ylabel='Condition'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at data\n",
    "sns.scatterplot(data=df, x=\"AREG\", y=\"Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmunologicalData:\n",
    "    \n",
    "    def __init__(self, as_frame):\n",
    "        self.data = None\n",
    "        self.target = None\n",
    "        self.feature_names = None\n",
    "        self.frame = None\n",
    "        \n",
    "        if as_frame:\n",
    "            df = pd.read_csv('data/HW2_Q1_DATA.csv')\n",
    "            \n",
    "            # encode categorical label??\n",
    "            def get_condition_num(condition):\n",
    "                if condition == \"CoV2\":\n",
    "                    return 1\n",
    "                elif condition == \"Kawasaki\":\n",
    "                    return 2\n",
    "                elif condition == \"MIS-C\":\n",
    "                    return 3\n",
    "                else:\n",
    "                    raise IllegalArgumentException(\"Condition not recognized.\")\n",
    "                    \n",
    "            df[\"Condition_Num\"]=df[\"Condition\"].apply(get_condition_num) \n",
    "            \n",
    "            self.frame = df\n",
    "            self.data = df.drop([\"Condition\", \"Condition_Num\"], axis=1)            \n",
    "            self.target = df[\"Condition_Num\"]           \n",
    "            self.feature_names = list(df.columns)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save column lists\n",
    "# regressor_cols = list([i for i in range(0,133)]) # columns 1 to 133\n",
    "# label_col = 134 # Condition_num column\n",
    "\n",
    "# # convert categorical label into number??\n",
    "# def get_condition_num(condition):\n",
    "#     if condition == \"CoV2\":\n",
    "#         return 1\n",
    "#     elif condition == \"Kawasaki\":\n",
    "#         return 2\n",
    "#     elif condition == \"MIS-C\":\n",
    "#         return 3\n",
    "#     else:\n",
    "#         raise IllegalArgumentException(\"Condition not recognized.\")\n",
    "    \n",
    "# df[\"Condition_Num\"]=df[\"Condition\"].apply(get_condition_num)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YraonsAGdhor"
   },
   "source": [
    "## Part 1.1: Filter-based Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7gLKzIwdrEb"
   },
   "source": [
    "### Part 1.1.1: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9-C8RSmdnwd"
   },
   "outputs": [],
   "source": [
    "# TODO: Apply a filter-based feature selection method of your choice using 10-fold cross validation \n",
    "#       and use the results to choose the top 20 features\n",
    "\n",
    "# TIP: Scikit-learn provides implementations of many useful statistical measures.\n",
    "\n",
    "#       Pearsons Correlation Coefficient: f_regression()\n",
    "#       ANOVA: f_classif()\n",
    "#       Chi-Squared: chi2()\n",
    "#       Mutual Information: mutual_info_classif() and mutual_info_regression()\n",
    "\n",
    "#      Also, SciPy provides implementations of many more statistics, such as\n",
    "#      Kendalls tau (kendalltau) and Spearmans rank correlation (spearmanr).\n",
    "\n",
    "\n",
    "# ?? goal is to identify features that are highly correlated and remove them, to have 20 left\n",
    "# ?? goal is to identify the 20 features that are most correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_regressors_and_label(df, rows, label_cols, label):\n",
    "#     '''Splits df into a DataFrame of regressors and a Series of the label column, then returns the result as a tuple of (Regressor DataFrame,Label Series).\n",
    "    \n",
    "#        df           dataframe to split\n",
    "#        rows         list of which rows to select for this fold, indexed from 0  \n",
    "#        label_cols   list of column names which are not regressors and should be removed from regressor set\n",
    "#        label        name of label column\n",
    "#     '''\n",
    "#     df_selected = df.iloc[rows]\n",
    "    \n",
    "#     df_regressors = df_selected.drop(label_cols, axis=1)\n",
    "#     s_label = df_selected[label]\n",
    "#     return (df_regressors,s_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single f-test on Pearson's correlation coefficient (learning example with single regressor column)\n",
    "high negative or positive correlation results in high F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regressor1  label1  extra\n",
      "0           1       6      5\n",
      "1           2       4      5\n",
      "2           3       5      5\n",
      "3           4       3      5\n",
      "4           5       2      5\n",
      "\n",
      "   regressor1\n",
      "0           1\n",
      "1           2\n",
      "2           3\n",
      "3           4\n",
      "4           5\n",
      "\n",
      "0    6\n",
      "1    4\n",
      "2    5\n",
      "3    3\n",
      "4    2\n",
      "Name: label1, dtype: int64\n",
      "\n",
      "            regressor1  label1\n",
      "regressor1         1.0    -0.9\n",
      "label1            -0.9     1.0\n",
      "\n",
      "[12.78947368]\n",
      "[0.03738607]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# test data\n",
    "a = np.array([[1, 6, 5], [2, 4, 5], [3, 5, 5], [4, 3, 5], [5, 2, 5]]) # create an array\n",
    "df_test=pd.DataFrame(data=a, columns=[\"regressor1\", \"label1\", \"extra\"])\n",
    "print(df_test)\n",
    "print()\n",
    "\n",
    "# split dataframe into separate regressors DataFrame and label Series\n",
    "X = df_test.drop([\"label1\", \"extra\"], axis=1)\n",
    "y = df_test[\"label1\"]\n",
    "print(X)\n",
    "print()\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "# pearson's correlation coefficient\n",
    "# The Pearson correlation evaluates the linear relationship between two continuous variables.\n",
    "print(df_test.drop(\"extra\", axis=1).corr(method='pearson')) # expecting -0.90\n",
    "print()\n",
    "\n",
    "# f-test of pearson's correlation coefficient\n",
    "F_scores, p_values = f_regression(X, y, center=True)\n",
    "print(F_scores) # expecting 12.78947368\n",
    "print(p_values) # expecting 0.03738607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single f-test on Pearson's correlation coefficient (actual data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # row_count = len(df.index)\n",
    "\n",
    "# # split data into training and test set\n",
    "# rows = [i for i in range(0,len(df.index))]\n",
    "\n",
    "# # split DataFrame into regressors and label\n",
    "# (X,y) = split_regressors_and_label(df, rows, label_cols=[\"Condition\", \"Condition_Num\"],label=\"Condition_Num\")\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# # f-test of pearson's correlation coefficient\n",
    "# F_scores, p_values = f_regression(X, y, center=True)\n",
    "# print(F_scores.shape) # one score for each regressor column\n",
    "# print(p_values.shape) # one p-value for each regressor column score\n",
    "\n",
    "\n",
    "# # build DataFrame of results\n",
    "# \n",
    "\n",
    "\n",
    "# # sort p values\n",
    "# # ?? how to sort without losing index to know which column this is\n",
    "# np.sort(F_scores) # find that there aren't 20 p-values under 0.05..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Pearson's correlation coefficient tests for 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# get data\n",
    "idata = ImmunologicalData(as_frame=True)\n",
    "X = idata.data\n",
    "y = idata.target\n",
    "\n",
    "\n",
    "# build DataFrame to store results\n",
    "df_result = pd.DataFrame(columns=['k','Regressor','F_score','P_value']).astype(dtype= {'k':'int64','Regressor':'object', 'F_score':'float64','P_value':'float64'})\n",
    "\n",
    "#?? how to remember which rows in which fold\n",
    "#?? where does k-fold come into the picture? test vs training data?\n",
    "#?? how to keep track of which column for which F_score?\n",
    "kf=KFold(n_splits=10, shuffle=False)  \n",
    "for k, (train, test) in enumerate(kf.split(X, y)):\n",
    "\n",
    "    # get training rows for this fold\n",
    "    X_train = X.iloc[train] \n",
    "    y_train = y.iloc[train]\n",
    "    \n",
    "    # run Pearson's correlation coefficient\n",
    "    f_scores, p_values = f_regression(X_train, y_train, center=True)\n",
    "                \n",
    "    for i, f_score in enumerate(f_scores):\n",
    "        \n",
    "        # add row to result DataFrame for each F-score\n",
    "        col_name = idata.feature_names[i]\n",
    "        p_value = p_values[i]\n",
    "        new_row = pd.Series([k+1,col_name,f_score,p_value], index = df_result.columns)\n",
    "        df_result = df_result.append(new_row, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Regressor    F_score       P_value\n",
      "59        HGF  49.816711  1.856227e-11\n",
      "51      FAM3B  48.003948  2.944484e-11\n",
      "79      ITGB6  34.119862  2.499567e-08\n",
      "100       OPG  31.586697  1.972983e-07\n",
      "119      STC1  31.120322  4.848779e-08\n",
      "47       EDAR  30.549715  6.217153e-08\n",
      "27     CLEC4C  27.522199  5.974571e-07\n",
      "23      CDCP1  21.292353  1.502960e-05\n",
      "121       TNF  17.330040  8.653982e-05\n",
      "73        IL6  17.161013  1.220006e-04\n",
      "67     IL-17A  15.419758  1.803032e-04\n",
      "19        CD5  14.299028  2.647015e-04\n",
      "46      DPP10  13.890368  2.951712e-04\n",
      "42     DCBLD2  13.070751  4.005152e-04\n",
      "12      CCL25  13.068090  4.579635e-04\n",
      "114      SIT1  12.370420  9.130655e-04\n",
      "26     CLEC4A  11.778288  1.287744e-03\n",
      "132       uPA  10.165089  3.137807e-03\n",
      "15       CCL4   9.454490  4.196223e-03\n",
      "127     TREM1   9.020582  4.074127e-03\n",
      "\n",
      "HGF, FAM3B, ITGB6, OPG, STC1, EDAR, CLEC4C, CDCP1, TNF, IL6, IL-17A, CD5, DPP10, DCBLD2, CCL25, SIT1, CLEC4A, uPA, CCL4, TREM1\n"
     ]
    }
   ],
   "source": [
    "# compute average F_score and p_value across all training sets\n",
    "# reset_index() to add Regressor column to DataFrame\n",
    "df_means=df_result.drop(\"k\",axis=1).groupby([\"Regressor\"]).mean().reset_index()\n",
    "\n",
    "# # filter out F_scores with p-value > 0.05\n",
    "# df_filtered=df_means[df_means['P_value']<=0.05]\n",
    "\n",
    "# select 20 regressors with largest F-scores\n",
    "df_top_20=df_means.sort_values(by=\"F_score\", ascending=False).head(20)\n",
    "print(df_top_20)\n",
    "print()\n",
    "\n",
    "list_top_20 = list(df_top_20[\"Regressor\"])\n",
    "print(*list_top_20, sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g80xDpM80UFQ"
   },
   "source": [
    "### Part 1.1.1: Answer\n",
    "\n",
    "List the top 20 features you found: \n",
    "**HGF, FAM3B, ITGB6, OPG, STC1, EDAR, CLEC4C, CDCP1, TNF, IL6, IL-17A, CD5, DPP10, DCBLD2, CCL25, SIT1, CLEC4A, uPA, CCL4, TREM1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtfRTOXz1Gt1"
   },
   "source": [
    "### Part 1.1.2: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIpEJ3OxzwmX"
   },
   "outputs": [],
   "source": [
    "# TODO: Create and plot a 20 x 20 correlation heat map using your features from part 1.1.1\n",
    "\n",
    "# TIP: 1. Pandas has a correlation functionality for dataframes\n",
    "#         https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\n",
    "#      2. Seaborn has a heatmap functionality\n",
    "#         https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select top 20 columns\n",
    "df_features=idata.data.loc[:][list_top_20]\n",
    "df_features.shape\n",
    "\n",
    "# heatmap\n",
    "cor=df_features.corr(method='pearson')\n",
    "sns.heatmap(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vhKTeVF3dyb"
   },
   "source": [
    "### Part 1.1.2: Answer\n",
    "\n",
    "**Plot the heatmap in one of the above cells or embed it as an image in this cell**\n",
    "\n",
    "What is the average of the values in the heatmap? **YOUR ANSWER HERE**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnIvvex64Hy5"
   },
   "source": [
    "### Part 1.1.3: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2J6Rt_y3bxO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Train a classifier using your top 1, top 2, ..., top 20 features from part 1.1.1\n",
    "      and plot the 10-fold cross-validated accuracy as a function of the number of features\n",
    "\n",
    "TIP: 1. scikit-learn has a great collection of classifiers: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "     2. scikit-learn also supports different ways of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAEcgInB6C_s"
   },
   "source": [
    "### Part 1.1.3: Answer\n",
    "\n",
    "**Include the plot as the output of one of the above cells or embed it as an image in this cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36OavcuX6SJY"
   },
   "source": [
    "### Part 1.1.4: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U53Y5qf-6wmf"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: 1. Devise a method for determining a threshold that can be used so separate\n",
    "         truly relevant features from those that are spurious\n",
    "      2. Apply this method to the data to obtain a new set of features\n",
    "      3. Re-train a classifier with the new features using 10-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdOdmAzK6wDC"
   },
   "source": [
    "### Part 1.1.4: Answer\n",
    "\n",
    "Briefly describe the method you devised for determinining a threshold for truly relevant features: **YOUR EXPLANATION HERE**\n",
    "\n",
    "List the new set of features obtained from applying your method to the data: **YOUR ANSWER HERE**\n",
    "\n",
    "What was the 10-fold cross-validated accuracy of the classifier trained with these new features? **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hwq6PMbR8Ffa"
   },
   "source": [
    "### Part 1.1.5: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHF7wT-O7-jO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: 1. Use a clustering algorithm of your choice to cluster\n",
    "         the features you found in part 1.1.4 into 10 clusters\n",
    "      2. Choose a representative feature from each cluster and\n",
    "         train a classifier with these features using 10-fold\n",
    "         cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-tene4Z8_I9"
   },
   "source": [
    "### Part 1.1.5: Answer\n",
    "\n",
    "List the representative features you chose from the 10 clusters: **YOUR ANSWER HERE**\n",
    "\n",
    "What was the 10-fold cross-validated accuracy of the classifier trained with these representative features? **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-np5K83j9WBw"
   },
   "source": [
    "## Part 1.2: Wrapper-based Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRpq-D719YMH"
   },
   "source": [
    "### Part 1.2.1: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbC1tQGP9Psa"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Apply a wrapper-based feature selection method of your choice to the data\n",
    "\n",
    "TIP: 1. Scikit learn has an implementation of recursive feature elimination (RFE)\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "     2. The mlxtend library has very thorough documentation and great options for sequential and exhaustive feature selection\n",
    "        http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\n",
    "        http://rasbt.github.io/mlxtend/user_guide/feature_selection/ExhaustiveFeatureSelector/\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JddzaAXu_OxA"
   },
   "source": [
    "### Part 1.2.1: Answer\n",
    "\n",
    "List the top features selected in at least 8 out of 10 folds: **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pd-11SenK0c7"
   },
   "source": [
    "### Part 1.2.2: Work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHI20iqrK4UG"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Create and plot a 20 x 20 correlation heat map using your features from part 1.2.1\n",
    "\n",
    "TIP: 1. Pandas has a correlation functionality for dataframes\n",
    "        https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\n",
    "     2. Seaborn has a heatmap functionality\n",
    "        https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VxDClm0LCsm"
   },
   "source": [
    "### Part 1.2.2: Answer\n",
    "\n",
    "**Plot the heatmap in one of the above cells or embed it as an image in this cell**\n",
    "\n",
    "What is the average of the values in the heatmap? **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oh3A5XELh94"
   },
   "source": [
    "### Part 1.2.3: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FttFZVQtLPQK"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Train a classifier using your features from part 1.2.1 with 10-fold cross validation\n",
    "\n",
    "TIP: 1. scikit-learn has a great collection of classifiers: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "     2. scikit-learn also supports different ways of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xk97RmEML0yE"
   },
   "source": [
    "### Part 1.2.3: Answer\n",
    "\n",
    "What was the 10-fold cross-validated accuracy of the classifier trained with these features? **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqHKhkYOMAwW"
   },
   "source": [
    "## Part 1.3: Embedded Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgLvWXaOMIbH"
   },
   "source": [
    "### Part 1.3.1: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4sMCTw-MQ98"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Apply an embedded feature selection method of your choice using 10-fold cross validation\n",
    "\n",
    "TIP: 1. See https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree \n",
    "        and/or https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "        for tree based methods\n",
    "     2. Check out the SelectFromModel functionality from \n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQNp1iEWOziu"
   },
   "source": [
    "### Part 1.3.1: Answer\n",
    "\n",
    "List the top features selected in at least 8 out of 10 folds: **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wOHLVUhO5nd"
   },
   "source": [
    "### Part 1.3.2: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1mNZU2jO-T5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Create and plot a 20 x 20 correlation heat map using your features from part 1.3.1\n",
    "\n",
    "TIP: 1. Pandas has a correlation functionality for dataframes\n",
    "        https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\n",
    "     2. Seaborn has a heatmap functionality\n",
    "        https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6keJov7lPEt8"
   },
   "source": [
    "### Part 1.3.2: Answer\n",
    "\n",
    "**Plot the heatmap in one of the above cells or embed it as an image in this cell**\n",
    "\n",
    "What is the average of the values in the heatmap? **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d8_sk7R_PHVZ"
   },
   "source": [
    "### Part 1.3.3: Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2xbbNARPLgb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Train a classifier using your features from part 1.3.1 with 10-fold cross validation\n",
    "\n",
    "TIP: 1. scikit-learn has a great collection of classifiers: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "     2. scikit-learn also supports different ways of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6jcKGtwPAxG"
   },
   "source": [
    "### Part 1.3.3: Answer\n",
    "\n",
    "What was the 10-fold cross-validated accuracy of the classifier trained with these features? **YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02-518/02-718 HW 2 Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CMU-02718-HW2_kernel",
   "language": "python",
   "name": "cmu-02718-hw2_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
